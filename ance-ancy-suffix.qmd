---
title: "R notebook for the corpus-based study of English suffixes -*ance* and -*ancy*"
date: 2025-03-18
author:
  - name:
      given: Ni Ketut
      family: Budiani
      corresponding: true
    affiliation:
      - id: complexico
        name: Computer-assisted Lexicology and Lexicography (CompLexico) research group, CIRHSS, Udayana University
        url: https://www.cirhss.org/complexico/
      - id: boel
        name: Bachelor of English Literature (BoEL), Faculty of Humanities, Udayana University
        url: https://sasing.unud.ac.id/
  - name:
      given: Gede Primahadi Wijaya
      family: Rajeg
    orcid: 0000-0002-2047-8621
    affiliation:
      - ref: complexico
      - ref: boel
  - name:
      given: I Made
      family: Netra
    orcid: 0000-0001-7186-2896
    affiliation:
      - ref: boel
license: "CC BY-NC-SA"
citation:
  type: software
  title: "R notebook for the corpus-based study of English suffixes -<i>ance</i> and -<i>ancy</i>"
  doi: "10.17605/OSF.IO/7YJ49"
  url: https://complexico.github.io/ance-ancy-suffix/
google-scholar: true
---

```{r setup, echo = FALSE}
library(tidyverse)
library(googlesheets4)
library(googledrive)
library(broom)
source("datasheet-url.R")
# dir.create("data-raw")
# dir.create("figures")

# googledrive::drive_mkdir("figures", path = drive_main_folder)
# Created Drive file:
# • figures <id: 18ppX_-Nr-dI-iQojYC5WHpGZi_dKojhA>
# With MIME type:
# • application/vnd.google-apps.folder

# googledrive::drive_mkdir("stats-output", path = drive_main_folder)
# Created Drive file:
# • stats-output <id: 1e_0dwXEH_qTTzUdDGNxI_LHQSFIS98qj>
# With MIME type:
# • application/vnd.google-apps.folder
```

```{r read-data}
# df <- read_sheet(ss = datasheet) <- run this regularly to check update
# write_rds(df, "data-raw/ance-ancy.rds")
df <- read_rds("data-raw/ance-ancy.rds")
unanalysed <- read_tsv("data-raw/unanalysed.csv") |> 
  mutate(SUFFIX = replace_na(SUFFIX, ""))
unanalysed1 <- unanalysed |> 
  filter(!is.na(ROOT), SUFFIX != "-mancy") |> 
  filter(FORM != "CIRCUMSTANCE") |> # historical relation with circum + stance
  mutate(SUFFIX = replace(SUFFIX, SUFFIX == "", "ancy")) |> 
  select(FORM, ROOT_new = ROOT, SUFFIX_new = SUFFIX, ETYMOLOGY_new = ETYMOLOGY)
```

```{r save-unknown-word, eval = FALSE, include = FALSE, echo = FALSE}
# this code generate a list of words that are not analysed in order to check if there are any words skipped while in fact relevant
df |> 
  filter(is.na(ROOT)) |> 
  select(FORM, ROOT) |> 
  distinct() |> 
  mutate(ROOT = replace_na(ROOT, "")) # |> 
  # write_excel_csv2("data-raw/unanalysed.csv")
```

```{r combine-gsheet-and-unanalysed}
# df_combined <- df |> 
#   left_join(unanalysed1,
#             by = join_by(FORM))|> 
#   mutate(ROOT = if_else(!is.na(ROOT_new),
#                         ROOT_new,
#                         ROOT),
#          ETYMOLOGY = if_else(!is.na(ETYMOLOGY_new),
#                              ETYMOLOGY_new,
#                              ETYMOLOGY),
#          SUFFIX = if_else(!is.na(SUFFIX_new),
#                           SUFFIX_new,
#                           SUFFIX)) |> 
#   select(!matches("_new"))

df_combined <- df
```


Try the current analysed data

```{r retrieve-relevant-data}
df_ok <- filter(df_combined, !is.na(ROOT))
# df_ok <- filter(df, !is.na(ROOT))
df_ok |> slice_sample(n = 10)
```

Run productivity analysis per suffix.

```{r productivity-by-affix, message = FALSE, warning = FALSE}
# drive_create("productivity-by-affix",
#              path = as_id("1e_0dwXEH_qTTzUdDGNxI_LHQSFIS98qj"),
#              type = "spreadsheet")
# Created Drive file:
# • productivity-by-affix <id: 1g9fw5PVUrSiR9TGA9tQlOBPektaZJaVMqBK7_wwAIOs>
# With MIME type:
# • application/vnd.google-apps.spreadsheet


prod_by_affix <- df_ok |> 
  
  # remove GENRE to re-calculate frequency of suffixes and their hapax
  select(-GENRE) |> 
  
  # to sum token frequency
  group_by(FORM, SUFFIX, ROOT) |> 
  summarise(n_token = sum(FREQ), .groups = "drop") |> 
  
  # determine the hapax
  mutate(is_hapax = if_else(n_token == 1, TRUE, FALSE)) |> 
  
  # to run productivity analysis
  group_by(SUFFIX) |> 
  summarise(n_type = n_distinct(FORM),
            n_token = sum(n_token),
            n_hapax = sum(is_hapax),
            hapax_per_token_ratio = n_hapax/n_token)

prod_by_affix |> 
  knitr::kable(col.names = c("Suffix", "Type Freq.", "Token Freq.", "No. Hapax", "Hapax per Token Ratio"))

# prod_by_affix |> 
#   rename(Suffix = SUFFIX,
#          `Type Freq.` = n_type,
#          `Token Freq.` = n_token,
#          `No. of Hapax` = n_hapax,
#          `Hapax per token ratio` = hapax_per_token_ratio) |> 
#   write_sheet(ss = "1g9fw5PVUrSiR9TGA9tQlOBPektaZJaVMqBK7_wwAIOs",
#               sheet = "Sheet1")

write_tsv(prod_by_affix, file = "data-out/productivity_overall_by_affix.tsv")

```

Run productivity analysis by genres.

```{r productivity-by-genre}
ance <- df_ok |> 
  filter(SUFFIX == "ance")

ance_word_freq <- ance |> 
  group_by(FORM) |> 
  summarise(FREQ = sum(FREQ))

ancy <- df_ok |> 
  filter(SUFFIX == "ancy")

ancy_word_freq <- ancy |> 
  group_by(FORM) |> 
  summarise(FREQ = sum(FREQ))

ance_prod <- ance |> 
  group_by(GENRE) |> 
  
  # determine the hapax in a given genre
  mutate(is_hapax = if_else(FREQ == 1, TRUE, FALSE)) |> 
  summarise(n_type = n_distinct(FORM),
            n_token = sum(FREQ),
            n_hapax = sum(is_hapax)) |> 
  ungroup() |> 
  mutate(suffix = "ancy")

ancy_prod <- ancy |> 
  group_by(GENRE) |> 
  
  # determine the hapax in a given genre
  mutate(is_hapax = if_else(FREQ == 1, TRUE, FALSE)) |> 
  summarise(n_type = n_distinct(FORM),
            n_token = sum(FREQ),
            n_hapax = sum(is_hapax)) |> 
  ungroup() |> 
  mutate(suffix = "ance")

genre_prod <- bind_rows(ance_prod, ancy_prod)

```

```{r fig-productivity-by-genre}

genre_prod |> 
  mutate(suffix = str_c("-", suffix, sep = "")) |> 
  ggplot(aes(x = GENRE, y = n_type, fill = suffix)) + 
  geom_col(position = position_dodge(width = .9)) +
  coord_flip() +
  theme_light(base_family = "serif") +
  labs(y = "Type frequency",
       fill = "Suffix",
       x = "Genre") +
  theme(legend.text = element_text(size = 13),
        legend.title = element_text(size = 17),
        axis.title.y = element_text(size = 17),
        axis.title.x = element_text(size = 17),
        axis.text.x = element_text(size = 13)) +
  scale_fill_discrete(breaks = c("-ancy", "-ance"))
# ggsave("figures/prod-by-genre.png", width = 6.5, height = 4.5, dpi = 300,
#        units = "in")

# googledrive::drive_upload("figures/prod-by-genre.png",
#                           path = as_id("18ppX_-Nr-dI-iQojYC5WHpGZi_dKojhA"),
#                           name = "productivity-by-genre.png")

```

Check the shared and distinct bases. This is operationalised via stripping off the -*ance* and -*ancy* strings from the FORM column.

```{r bases-sharing-or-distinct}
ance_form <- ance_word_freq |> 
  mutate(BASE = str_replace(FORM, "ANCE$", ""),
         suffix = "ance")

ancy_form <- ancy_word_freq |> 
  mutate(BASE = str_replace(FORM, "ANCY$", ""),
         suffix = "ancy")

all_ance_ancy <- bind_rows(ance_form, ancy_form)

all_bases <- unique(c(ance_form$BASE, ancy_form$BASE))

shared_ance_ancy <- intersect(ance_form$BASE, ancy_form$BASE)
shared_ance_ancy_prop <- round((length(shared_ance_ancy)/length(all_bases)) * 100, 2)

only_ance <- setdiff(ance_form$BASE, ancy_form$BASE)
only_ance_prop <- round((length(only_ance)/length(all_bases)) * 100, 2)

only_ancy <- setdiff(ancy_form$BASE, ance_form$BASE)
only_ancy_prop <- round((length(only_ancy)/length(all_bases)) * 100, 2)
```

Out of the total `r length(all_bases)` bases, only `r shared_ance_ancy_prop`% (i.e., `r length(shared_ance_ancy)` bases) are shared (i.e., appear with -*ance* and -*ancy*) but the frequency of occurrence of these shared bases with the suffixes are not equal.

```{r bases-sharing-table, message = FALSE, warning = FALSE}
all_ance_ancy_tb <- all_ance_ancy |> 
  filter(BASE %in% shared_ance_ancy) |> 
  select(-FORM) |> 
  pivot_wider(names_from = "suffix", values_from = "FREQ") |> 
  mutate(BASE = str_c(BASE, "ANC(E/Y)", sep = "")) |> 
  arrange(desc(ancy))

write_tsv(all_ance_ancy_tb, "data-out/all_ance_ancy_tb.tsv")

all_ance_ancy_tb |> 
  arrange(BASE) |> 
  knitr::kable()
```


# Binomial test

```{r binom, warning = FALSE}
all_ance_ancy_tb_binom <- all_ance_ancy_tb |> 
  mutate(binom = map2(ance, 
                      ancy, 
                      ~binom.test(.x,
                                  sum(c(.x, .y)),
                                  .5))) |> 
  mutate(binom = map(binom, ~tidy(.))) |> 
  unnest_wider(binom) |> 
  mutate(p_holm = p.adjust(p.value, method = "holm")) |> 
  arrange(BASE) |> 
  mutate(across(matches("(^estimate|^conf)"), ~round(., digits = 4)))
all_ance_ancy_tb_binom |> 
  knitr::kable(caption = "Binomial tests for base distribution between -*ance* and -*ancy*")
write_tsv(all_ance_ancy_tb_binom, file = "data-out/interchangeable-binom-test.tsv")
```

